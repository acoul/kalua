#!/bin/sh

# we need a monotonic counter for both: SCHEDULER / SCHEDULER_IMPORTANT
# with 8 digits -> max = 1157 days; note: var PID is the uptime
PID=;read -r PID _ </proc/uptime
SCHEDULER=${SCHEDULER-/tmp/SCHEDULER/job_$(printf %08.0f ${PID%.*}; mkdir -p /tmp/SCHEDULER)}
SCHEDULER_QUEUE='/tmp/SCHEDULER/*'
SCHEDULER_IMPORTANT=${SCHEDULER_IMPORTANT-/tmp/SCHEDULER/important_$(printf %08.0f $$)}
SCHEDULER_IMPORTANT_QUEUE='/tmp/SCHEDULER/important_*'

# TODO: start task @specific time (e.g. "in 32mins")

_scheduler_queue_purge()
{
	_log it purge_queues daemon info "removing"
	rm $SCHEDULER_QUEUE

	return 0
}

_scheduler_queue_list()
{
	local funcname="scheduler_list_queue"
	local option="$1"
	local empty1 empty2

	_log it $funcname daemon debug "working with option: '$option'"

	echo "# actual,running queue: /tmp/scheduler.log"
	cat '/tmp/scheduler.log' 2>/dev/null || {
		echo -en "# empty!\n\n"
		empty1="true"
	}

	echo -en "\n# waiting queue: (important + normal)\n"
	cat $SCHEDULER_QUEUE 2>/dev/null || {
		echo -en "# empty!\n\n"
		empty2="true"
	}

	[ "$option" = "is_empty" ] && {
		if [ "${empty1}${empty2}" = "truetrue" ]; then
			return 0
		else
			return 1
		fi
	}
}

_scheduler_print_usage ()
{
	local FUNC="scheduler_print_usage"

	_log it $FUNC daemon info "working"

	cat <<EOF

Sens:	 Adds program calls to a queue and executes all
	 these calls step by step. This prevents high
	 cpu-load and/or memory-consumption, but is not
	 executed at an exact timestamp.

Usage:	 $0 -option1 -option2 -optionN

Options: -a "TASK"   adds an TASK to queue, where TASK can be keyword
	 -r          runs the queue, step by step
	 -l          lists running and waitung queue
	 -p	     purge all queues
	 -P	     gateway ping-test
	 -o	     special: checks for incoming olsr-packets and
		     restarts daemon with new conf if neccessary
	 -u	     check syslog for kernel-oops, reboot if needed
	 -S "name"   load a set of scheduled services according to actual time

Example: $0 -s3 -a do_this -a do_that -r -a do_another_thing -r

	 This invokes a sleep for 3 seconds,
	 adds "do_this" to queue, then adds "do_that" to queue, then
	 runs the queue, then adds an user-defined program call to
	 queue, then runs the queue. Keywords must be defined in
	 _scheduler(). Ofcourse you should only use the queue, if
	 exact executing-time of your program does'nt really matter.

	 $0 -A "program1 arg1" -a "program2 arg1 arg2" -l

	 This immediately start "program1" with "arg1", than adds an
	 user-defined programm call with args and then lists all queues.

EOF
}

_scheduler_check_if_every_Nth_minute()
{
	# some tasks should be repeated regulary, but NOT on the same
	# time on every node in the mesh. so we need a way the schedule
	# a script every X minutes based on uptime and not on daytime,so:
	# check every min, if uptime is divisor of X (without a rest)

	local UPTIME="$( _system uptime min )"	# e.g. uptime = 60 and
	local CARRYOVER=$(( UPTIME % $1 ))	# e.g. every = 55 min : 60 % 55 = 5

	[ "$CARRYOVER" -eq 0 ] && {
		_log it scheduler_check_if_every_Nth_minute daemon debug "call '$2' for ${1}th minute, uptime: $UPTIME"
		return 0
	}

	return 1
}

_scheduler_wait_till_cpuload_is_low()
{
	local funcname='scheduler_wait_till_cpuload_is_low'
	local task="$1"
	local pause=23

	bool_true 'system.@monitoring[0].ignore_load' && return 0
	_weblogin authserver is_myself && return 0
	[ -e '/tmp/cron.webcam' ] && return 0

	while _system load 1min quiet; test $LOAD -gt 80 ; do {
		_log it $funcname daemon info "PID: $$ - load: $LOAD - waiting $pause sec for '$task'"
		sleep $pause
		[ $( _system uptime sec ) -lt 3600 ] && return 0
	} done
}

_scheduler_allow_run()
{
	local funcname="scheduler_allow_run"
	local lockfile="$1"

	[ -e "$lockfile" ] || return 0
	[ -e "$TMPDIR/$funcname" ] && return 0		# override: FIXME!

	if [ $( _stopwatch stop "$lockfile.start" interim,nolog,seconds ) -gt 3600 ]; then
		_log it $funcname daemon alert 'removing lockfile, which seems to be left by accident'
		rm "$lockfile" "$lockfile.start"
		return 0
	else
		_log it $funcname daemon debug "will not allow, see: $lockfile"
		return 1
	fi
}

_scheduler_run()
{
	local funcname='scheduler_run'
	local file line strong_debug lastpart without_first_underliner first_word without_first_underliner age length
	local logfile='/tmp/scheduler.log'
	local newline='
'
	_scheduler allow_run "$logfile" || return 1
	touch "$logfile" '/tmp/scheduler.mark_starttime'

	case "$CONFIG_PROFILE" in
		liszt28*)
			[ -z "$LOWMEM" -a $OPENWRT_REV -gt 0 ] && strong_debug='true'
		;;
	esac

	# SCHEDULER_QUEUE includes IMPORTANT (e.g. important_*) and
	# NORMAL job-queue (e.g. job_*) - via globbing *i*mportant comes before *j*ob
	for file in $SCHEDULER_QUEUE; do {
		[ -e "$file" ] || continue	# empty queue, so globbing does not expand

		while read -r line; do {
			if grep -sq ^"$line"$ "$logfile"; then
				# we only execute the LAST occurence of a job,
				# so we get more recent values/data
				_log it $funcname daemon debug "ignoring twin '$line'"
			else
				case "$line" in
					'_'*)   # seems like a kalua-function, e.g. _vpn_adduser argX
						case "$line" in
							*' '*' '*)
								# e.g. '_sms_send bla blubb' = 2 spaces or more
								without_first_underliner="${line#_}"		# sms_send bla blubb
								first_word="${without_first_underliner%_*}"	# sms

								if [ -e "/etc/kalua/$first_word" ]; then
									_log it $funcname daemon info "2 spaces, needs rewrite: line: '$line'"
									lastpart="${without_first_underliner#*_}"	# send bla blubb
									line="_$first_word $lastpart"
									_log it $funcname daemon info "2 spaces, rewrote: '$line'"
								else
									_log it $funcname daemon debug "rewrite unneeded: '$line'"
								fi
							;;
							*' '*)
								# OK: has a 'space' e.g. '_system load'
							;;
							*)
								# e.g. '_netfilter_splash_autoadd' -> '_netfilter splash_autoadd'

								# TODO: fix this in kalua_init
								# needs rewrite, replace second '_' with a 'space'
								without_first_underliner="${line#_}"
								line="_${without_first_underliner/_/ }"		# replace 1st occurence
							;;
						esac
					;;
				esac

				case "$line" in
					*"$newline"*)
						# likely in error
						strong_debug='true'
					;;
				esac

				# FIXME! how can it happen that we have invalid lines, e.g:
				# _db user device add '83
				case "$strong_debug" in
					'true')
						echo "$line" >"$logfile.debug"
						sh -n "$logfile.debug" || {
							_log it $funcname daemon alert "bad line: $line"
							line='true'
						}
					;;
				esac

				echo "$line" >>"$logfile"
				_scheduler wait_till_cpuload_is_low "$line"
				_stopwatch start "$logfile.start" global
				_log it $funcname daemon debug "[START] '$line'"
#				_stopwatch start '/tmp/PROFILER'
				case "$line" in
					# first 2 are: arguments in quotation marks
					*" '"*|*' "'*|*'|'*|*'<'*|*'>'*|*';'*|*' && '*|*' || '*)
						# TODO: debug mode also here?
						eval $line
					;;
					*)
						# TODO: if '$line' leads to a 'Segmentation fault' this breaks here
						case "$strong_debug" in
							'true')
								set -x
								$line 2>>"$logfile.debug"
								set +x
							;;
							*)
								$line
							;;
						esac
					;;
				esac
#				local time=$( _stopwatch stop '/tmp/PROFILER' nolog )
#				echo "$line - $time" >>'/tmp/PROFILER.data'

				_log it $funcname daemon debug "[READY] '$line'"
				_watch coredump "after: $line"

				case "$line" in
					'_firmware check_forced_upgrade'|'_firmware burn')
						_log it $funcname daemon info "[OK] premature exit after '$line'"
						break
					;;
				esac
			fi
		} done <"$file"

		rm "$file" 2>/dev/null

		_file age '/tmp/scheduler.mark_starttime' -gt 60 && {
			# otherwise maybe 'IMPORTANT' jobs must wait too long
			age="$( _file age '/tmp/scheduler.mark_starttime' sec )"
			length=0
			for _ in $SCHEDULER_QUEUE; do test -e "$_" && length=$(( length + 1 )); done
			_log it $funcname daemon info "[OK] aborting run, age: $age sec - $length jobs in queue"
			break
		}
	} done

	rm "$logfile"
}
